{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eff99350",
      "metadata": {},
      "source": [
        "# Match Plants: Same or Different — Ablation: no pretrain — Group split by image ID\n",
        "\n",
        "This notebook trains a model that looks at two plant photos and decides if they show the **same plant** or **different plants**.\n",
        "\n",
        "You will get:\n",
        "- A trained model.\n",
        "- A CSV file `yourname_results.csv` with predictions for the test pairs.\n",
        "\n",
        "No coding experience is required to run it: just run the cells in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "37bd89e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:07.556140Z",
          "iopub.status.busy": "2026-01-27T07:29:07.556001Z",
          "iopub.status.idle": "2026-01-27T07:29:09.534128Z",
          "shell.execute_reply": "2026-01-27T07:29:09.533698Z"
        }
      },
      "outputs": [],
      "source": [
        "# Basic tools and settings\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\n# Repeatable results\nnp.random.seed(1)\ntorch.manual_seed(1)\n\n# Use Apple GPU (MPS) if available, otherwise fall back to CPU\nif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n    DEVICE = \"mps\"\nelif torch.cuda.is_available():\n    DEVICE = \"cuda\"\nelse:\n    DEVICE = \"cpu\"\n\n# File locations\nDATA_DIR = \"/Users/shirong/match_plants/data\"\nIMG_DIR = os.path.join(DATA_DIR, \"data\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train_data.csv\")\nTEST_CSV = os.path.join(DATA_DIR, \"test_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67957d41",
      "metadata": {},
      "source": [
        "## Step 1: Load the pair lists\n",
        "\n",
        "`train_data.csv` includes the correct answer (`class`) for each pair.\n",
        "`test_data.csv` does **not** include answers, so we predict them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f1432312",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.535576Z",
          "iopub.status.busy": "2026-01-27T07:29:09.535459Z",
          "iopub.status.idle": "2026-01-27T07:29:09.546343Z",
          "shell.execute_reply": "2026-01-27T07:29:09.546017Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device mps\n",
            "train (2400, 4)\n",
            "test (600, 3)\n",
            "class\n",
            "0    1601\n",
            "1     799\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair_Num</th>\n",
              "      <th>img_idx1</th>\n",
              "      <th>img_idx2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>372</td>\n",
              "      <td>182</td>\n",
              "      <td>684</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71</td>\n",
              "      <td>477</td>\n",
              "      <td>990</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2561</td>\n",
              "      <td>769</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104</td>\n",
              "      <td>906</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2149</td>\n",
              "      <td>123</td>\n",
              "      <td>344</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pair_Num  img_idx1  img_idx2  class\n",
              "0       372       182       684      0\n",
              "1        71       477       990      0\n",
              "2      2561       769       240      1\n",
              "3      1104       906        36      0\n",
              "4      2149       123       344      1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\nprint(\"device\", DEVICE)\nprint(\"train\", train_df.shape)\nprint(\"test\", test_df.shape)\nprint(train_df[\"class\"].value_counts())\ntrain_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89aa5d3",
      "metadata": {},
      "source": [
        "## Step 2: Define how to read image pairs\n",
        "\n",
        "This `Dataset` tells PyTorch how to load two images and (for training) the label that says whether they match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4839612",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.547443Z",
          "iopub.status.busy": "2026-01-27T07:29:09.547390Z",
          "iopub.status.idle": "2026-01-27T07:29:09.549700Z",
          "shell.execute_reply": "2026-01-27T07:29:09.549385Z"
        }
      },
      "outputs": [],
      "source": [
        "class PairDataset(Dataset):\n    def __init__(self, df, transform, is_test=False):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # Read two images by ID\n        img1 = Image.open(os.path.join(IMG_DIR, f\"{row.img_idx1}.jpg\")).convert(\"RGB\")\n        img2 = Image.open(os.path.join(IMG_DIR, f\"{row.img_idx2}.jpg\")).convert(\"RGB\")\n        # Convert images into tensors\n        x1 = self.transform(img1)\n        x2 = self.transform(img2)\n        if self.is_test:\n            return x1, x2\n        # For training, also return the label\n        return x1, x2, torch.tensor(row[\"class\"], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35ebdae",
      "metadata": {},
      "source": [
        "## Step 3: Image preprocessing\n",
        "\n",
        "We resize and normalize images so the pretrained model can work well.\n",
        "For training we also use small random changes (augmentation) to improve generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c0d42eb2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.550545Z",
          "iopub.status.busy": "2026-01-27T07:29:09.550500Z",
          "iopub.status.idle": "2026-01-27T07:29:09.552675Z",
          "shell.execute_reply": "2026-01-27T07:29:09.552332Z"
        }
      },
      "outputs": [],
      "source": [
        "# ImageNet normalization values\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\n# Training images get random crops and flips\ntrain_tf = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\n# Validation and test images use fixed center crop\nval_tf = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb04efe1",
      "metadata": {},
      "source": [
        "## Step 4: The model (Siamese ResNet18)\n",
        "\n",
        "Each image is passed through the same pretrained ResNet18 to get a feature vector.\n",
        "We then compare the two vectors and predict if they are the same plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "db0a80d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.553574Z",
          "iopub.status.busy": "2026-01-27T07:29:09.553524Z",
          "iopub.status.idle": "2026-01-27T07:29:09.555786Z",
          "shell.execute_reply": "2026-01-27T07:29:09.555472Z"
        }
      },
      "outputs": [],
      "source": [
        "class SiameseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Pretrained backbone that turns an image into a 512-dim vector\n        backbone = torchvision.models.resnet18(\n            weights=None\n        )\n        backbone.fc = nn.Identity()\n        self.backbone = backbone\n\n        # Small head that compares two image vectors\n        self.head = nn.Sequential(\n            nn.Linear(512 * 2, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1),\n        )\n\n    def forward(self, x1, x2):\n        f1 = self.backbone(x1)\n        f2 = self.backbone(x2)\n        # Compare the two features\n        feat = torch.cat([torch.abs(f1 - f2), f1 * f2], dim=1)\n        # Output a single logit (later turned into a probability)\n        return self.head(feat).squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c7579b5",
      "metadata": {},
      "source": [
        "## Step 5: Train and pick the best threshold\n",
        "\n",
        "We split the training pairs into a train and validation set.\n",
        "During validation we search for the best probability threshold `best_t` that maximizes F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a13152df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.556755Z",
          "iopub.status.busy": "2026-01-27T07:29:09.556707Z",
          "iopub.status.idle": "2026-01-27T07:31:37.753588Z",
          "shell.execute_reply": "2026-01-27T07:31:37.753227Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 loss 0.9447 val_f1 0.5086 best_t 0.49\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 loss 0.9277 val_f1 0.5191 best_t 0.44\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 loss 0.9180 val_f1 0.5477 best_t 0.40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 loss 0.9064 val_f1 0.5632 best_t 0.37\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 loss 0.8900 val_f1 0.5286 best_t 0.45\n",
            "best overall 0.5632183908045977 0.37\n"
          ]
        }
      ],
      "source": [
        "# Train/val split by image IDs (avoid leakage)\nall_ids = pd.Index(sorted(set(train_df[\"img_idx1\"]).union(set(train_df[\"img_idx2\"]))))\ntrain_ids, val_ids = train_test_split(\n    all_ids, test_size=0.2, random_state=42\n)\ntrain_ids = set(train_ids)\nval_ids = set(val_ids)\n\ntrain_pairs = train_df[\n    train_df[\"img_idx1\"].isin(train_ids) & train_df[\"img_idx2\"].isin(train_ids)\n]\nval_pairs = train_df[\n    train_df[\"img_idx1\"].isin(val_ids) & train_df[\"img_idx2\"].isin(val_ids)\n]\n\nprint(\"train pairs\", train_pairs.shape, \"val pairs\", val_pairs.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aa9083",
      "metadata": {},
      "source": [
        "## Step 6: Train a final model on all training data\n",
        "\n",
        "Now we train once more using **all** training pairs.\n",
        "We reuse `best_t` from the validation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51a1db1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:31:37.754804Z",
          "iopub.status.busy": "2026-01-27T07:31:37.754737Z",
          "iopub.status.idle": "2026-01-27T07:34:25.696624Z",
          "shell.execute_reply": "2026-01-27T07:34:25.696148Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 1 loss 0.9316\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 2 loss 0.9258\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 3 loss 0.8967\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 4 loss 0.8837\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 5 loss 0.8432\n"
          ]
        }
      ],
      "source": [
        "full_ds = PairDataset(train_df, train_tf)\nfull_loader = DataLoader(full_ds, batch_size=16, shuffle=True, num_workers=0)\n\nfinal_model = SiameseNet().to(DEVICE)\n\npos = float(train_df[\"class\"].sum())\nneg = float(len(train_df) - pos)\npos_weight = torch.tensor([neg / pos], dtype=torch.float32, device=DEVICE)\n\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.AdamW(final_model.parameters(), lr=1e-4, weight_decay=1e-4)\n\nfor epoch in range(1, 6):\n    final_model.train()\n    total_loss = 0.0\n    for x1, x2, y in full_loader:\n        x1 = x1.to(DEVICE)\n        x2 = x2.to(DEVICE)\n        y = y.to(DEVICE)\n        optimizer.zero_grad()\n        logits = final_model(x1, x2)\n        loss = criterion(logits, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * y.size(0)\n    print(f\"final epoch {epoch} loss {total_loss/len(full_ds):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e33ec7",
      "metadata": {},
      "source": [
        "## Step 7: Predict for the test pairs\n",
        "\n",
        "We apply the trained model to the test pairs and write `yourname_results.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d46912c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:34:25.697780Z",
          "iopub.status.busy": "2026-01-27T07:34:25.697709Z",
          "iopub.status.idle": "2026-01-27T07:34:29.532624Z",
          "shell.execute_reply": "2026-01-27T07:34:29.532135Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair_Num</th>\n",
              "      <th>Predicted_Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1278</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>894</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pair_Num  Predicted_Result\n",
              "0      2458                 1\n",
              "1      2172                 1\n",
              "2      2658                 0\n",
              "3      1278                 0\n",
              "4       894                 1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict on test set and write submission\nfinal_model.eval()\n\ntest_ds = PairDataset(test_df, val_tf, is_test=True)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)\n\nall_probs = []\nwith torch.no_grad():\n    for x1, x2 in test_loader:\n        x1 = x1.to(DEVICE)\n        x2 = x2.to(DEVICE)\n        logits = final_model(x1, x2)\n        probs = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n        all_probs.append(probs)\n\nall_probs = np.concatenate(all_probs)\n\n# Turn probabilities into 0/1 predictions using best_t\npreds = (all_probs >= best_t).astype(int)\n\nout = pd.DataFrame({\n    \"Pair_Num\": test_df[\"Pair_Num\"],\n    \"Predicted_Result\": preds,\n})\n\nout_path = \"shirong_results.csv\"\nout.to_csv(out_path, index=False)\n\nout.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8041cec",
      "metadata": {},
      "source": [
        "## Notes and tips\n",
        "\n",
        "- `val_f1` is the F1 score on the validation split. Higher is better.\n",
        "- `best_t` is the best probability threshold found for F1.\n",
        "- The test file has no labels, so the output is a prediction only.\n",
        "- Rename `yourname_results.csv` to match the required naming rule."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "eoitek",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}