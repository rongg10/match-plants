{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eff99350",
      "metadata": {},
      "source": [
        "# Match Plants: Same or Different — Ablation: no pretrain — Group split by image ID\n",
        "\n",
        "This notebook trains a model that looks at two plant photos and decides if they show the **same plant** or **different plants**.\n",
        "\n",
        "You will get:\n",
        "- A trained model.\n",
        "- A CSV file `yourname_results.csv` with predictions for the test pairs.\n",
        "\n",
        "No coding experience is required to run it: just run the cells in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "37bd89e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:07.556140Z",
          "iopub.status.busy": "2026-01-27T07:29:07.556001Z",
          "iopub.status.idle": "2026-01-27T07:29:09.534128Z",
          "shell.execute_reply": "2026-01-27T07:29:09.533698Z"
        }
      },
      "outputs": [],
      "source": [
        "# Basic tools and settings\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Repeatable results\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Use Apple GPU (MPS) if available, otherwise fall back to CPU\n",
        "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    DEVICE = \"mps\"\n",
        "elif torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "# File locations\n",
        "DATA_DIR = \"data\"\n",
        "IMG_DIR = os.path.join(DATA_DIR, \"data\")\n",
        "TRAIN_CSV = os.path.join(DATA_DIR, \"train_data.csv\")\n",
        "TEST_CSV = os.path.join(DATA_DIR, \"test_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67957d41",
      "metadata": {},
      "source": [
        "## Step 1: Load the pair lists\n",
        "\n",
        "`train_data.csv` includes the correct answer (`class`) for each pair.\n",
        "`test_data.csv` does **not** include answers, so we predict them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f1432312",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.535576Z",
          "iopub.status.busy": "2026-01-27T07:29:09.535459Z",
          "iopub.status.idle": "2026-01-27T07:29:09.546343Z",
          "shell.execute_reply": "2026-01-27T07:29:09.546017Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device mps\n",
            "train (2400, 4)\n",
            "test (600, 3)\n",
            "class\n",
            "0    1601\n",
            "1     799\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair_Num</th>\n",
              "      <th>img_idx1</th>\n",
              "      <th>img_idx2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>372</td>\n",
              "      <td>182</td>\n",
              "      <td>684</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71</td>\n",
              "      <td>477</td>\n",
              "      <td>990</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2561</td>\n",
              "      <td>769</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1104</td>\n",
              "      <td>906</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2149</td>\n",
              "      <td>123</td>\n",
              "      <td>344</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pair_Num  img_idx1  img_idx2  class\n",
              "0       372       182       684      0\n",
              "1        71       477       990      0\n",
              "2      2561       769       240      1\n",
              "3      1104       906        36      0\n",
              "4      2149       123       344      1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "\n",
        "print(\"device\", DEVICE)\n",
        "print(\"train\", train_df.shape)\n",
        "print(\"test\", test_df.shape)\n",
        "print(train_df[\"class\"].value_counts())\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89aa5d3",
      "metadata": {},
      "source": [
        "## Step 2: Define how to read image pairs\n",
        "\n",
        "This `Dataset` tells PyTorch how to load two images and (for training) the label that says whether they match."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a4839612",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.547443Z",
          "iopub.status.busy": "2026-01-27T07:29:09.547390Z",
          "iopub.status.idle": "2026-01-27T07:29:09.549700Z",
          "shell.execute_reply": "2026-01-27T07:29:09.549385Z"
        }
      },
      "outputs": [],
      "source": [
        "class PairDataset(Dataset):\n",
        "    def __init__(self, df, transform, is_test=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # Read two images by ID\n",
        "        img1 = Image.open(os.path.join(IMG_DIR, f\"{row.img_idx1}.jpg\")).convert(\"RGB\")\n",
        "        img2 = Image.open(os.path.join(IMG_DIR, f\"{row.img_idx2}.jpg\")).convert(\"RGB\")\n",
        "        # Convert images into tensors\n",
        "        x1 = self.transform(img1)\n",
        "        x2 = self.transform(img2)\n",
        "        if self.is_test:\n",
        "            return x1, x2\n",
        "        # For training, also return the label\n",
        "        return x1, x2, torch.tensor(row[\"class\"], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c35ebdae",
      "metadata": {},
      "source": [
        "## Step 3: Image preprocessing\n",
        "\n",
        "We resize and normalize images so the pretrained model can work well.\n",
        "For training we also use small random changes (augmentation) to improve generalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c0d42eb2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.550545Z",
          "iopub.status.busy": "2026-01-27T07:29:09.550500Z",
          "iopub.status.idle": "2026-01-27T07:29:09.552675Z",
          "shell.execute_reply": "2026-01-27T07:29:09.552332Z"
        }
      },
      "outputs": [],
      "source": [
        "# ImageNet normalization values\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Training images get random crops and flips\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "# Validation and test images use fixed center crop\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb04efe1",
      "metadata": {},
      "source": [
        "## Step 4: The model (Siamese ResNet18)\n",
        "\n",
        "Each image is passed through the same pretrained ResNet18 to get a feature vector.\n",
        "We then compare the two vectors and predict if they are the same plant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "db0a80d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.553574Z",
          "iopub.status.busy": "2026-01-27T07:29:09.553524Z",
          "iopub.status.idle": "2026-01-27T07:29:09.555786Z",
          "shell.execute_reply": "2026-01-27T07:29:09.555472Z"
        }
      },
      "outputs": [],
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Pretrained backbone that turns an image into a 512-dim vector\n",
        "        backbone = torchvision.models.resnet18(\n",
        "            weights=None\n",
        "        )\n",
        "        backbone.fc = nn.Identity()\n",
        "        self.backbone = backbone\n",
        "\n",
        "        # Small head that compares two image vectors\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(512 * 2, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.backbone(x1)\n",
        "        f2 = self.backbone(x2)\n",
        "        # Compare the two features\n",
        "        feat = torch.cat([torch.abs(f1 - f2), f1 * f2], dim=1)\n",
        "        # Output a single logit (later turned into a probability)\n",
        "        return self.head(feat).squeeze(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c7579b5",
      "metadata": {},
      "source": [
        "## Step 5: Train and pick the best threshold\n",
        "\n",
        "We split the training pairs into a train and validation set.\n",
        "During validation we search for the best probability threshold `best_t` that maximizes F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a13152df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:29:09.556755Z",
          "iopub.status.busy": "2026-01-27T07:29:09.556707Z",
          "iopub.status.idle": "2026-01-27T07:31:37.753588Z",
          "shell.execute_reply": "2026-01-27T07:31:37.753227Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 loss 0.9447 val_f1 0.5086 best_t 0.49\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 loss 0.9277 val_f1 0.5191 best_t 0.44\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 loss 0.9180 val_f1 0.5477 best_t 0.40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 loss 0.9064 val_f1 0.5632 best_t 0.37\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 loss 0.8900 val_f1 0.5286 best_t 0.45\n",
            "best overall 0.5632183908045977 0.37\n"
          ]
        }
      ],
      "source": [
        "# Train/val split by image IDs (avoid leakage)\nall_ids = pd.Index(sorted(set(train_df[\"img_idx1\"]).union(set(train_df[\"img_idx2\"]))))\ntrain_ids, val_ids = train_test_split(\n    all_ids, test_size=0.2, random_state=42\n)\ntrain_ids = set(train_ids)\nval_ids = set(val_ids)\n\ntrain_pairs = train_df[\n    train_df[\"img_idx1\"].isin(train_ids) & train_df[\"img_idx2\"].isin(train_ids)\n]\nval_pairs = train_df[\n    train_df[\"img_idx1\"].isin(val_ids) & train_df[\"img_idx2\"].isin(val_ids)\n]\n\nprint(\"train pairs\", train_pairs.shape, \"val pairs\", val_pairs.shape)\n\ntrain_ds = PairDataset(train_pairs, train_tf)\nval_ds = PairDataset(val_pairs, val_tf)\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=0)\n\nmodel = SiameseNet().to(DEVICE)\n\n# Class weighting to handle class imbalance\npos = float(train_pairs[\"class\"].sum())\nneg = float(len(train_pairs) - pos)\npos_weight = torch.tensor([neg / pos], dtype=torch.float32, device=DEVICE)\n\n# Binary cross-entropy with logits\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n\nbest_f1 = 0.0\nbest_t = 0.5\n\nfor epoch in range(1, 6):\n    model.train()\n    total_loss = 0.0\n    for x1, x2, y in train_loader:\n        x1 = x1.to(DEVICE)\n        x2 = x2.to(DEVICE)\n        y = y.to(DEVICE)\n        optimizer.zero_grad()\n        logits = model(x1, x2)\n        loss = criterion(logits, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * y.size(0)\n\n    # Validation: compute probabilities and tune the threshold\n    model.eval()\n    all_probs = []\n    all_y = []\n    with torch.no_grad():\n        for x1, x2, y in val_loader:\n            x1 = x1.to(DEVICE)\n            x2 = x2.to(DEVICE)\n            logits = model(x1, x2)\n            probs = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n            all_probs.append(probs)\n            all_y.append(y.numpy().astype(np.float32))\n    all_probs = np.concatenate(all_probs)\n    all_y = np.concatenate(all_y)\n\n    best_epoch_t, best_epoch_f1 = 0.5, 0.0\n    for t in np.linspace(0.1, 0.9, 81):\n        pred = (all_probs >= t).astype(int)\n        f1 = f1_score(all_y, pred)\n        if f1 > best_epoch_f1:\n            best_epoch_f1 = f1\n            best_epoch_t = t\n\n    if best_epoch_f1 > best_f1:\n        best_f1 = best_epoch_f1\n        best_t = best_epoch_t\n\n    print(f\"epoch {epoch} loss {total_loss/len(train_ds):.4f} val_f1 {best_epoch_f1:.4f} best_t {best_epoch_t:.2f}\")\n\nprint(\"best overall\", best_f1, best_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48aa9083",
      "metadata": {},
      "source": [
        "## Step 6: Train a final model on all training data\n",
        "\n",
        "Now we train once more using **all** training pairs.\n",
        "We reuse `best_t` from the validation step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "51a1db1a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:31:37.754804Z",
          "iopub.status.busy": "2026-01-27T07:31:37.754737Z",
          "iopub.status.idle": "2026-01-27T07:34:25.696624Z",
          "shell.execute_reply": "2026-01-27T07:34:25.696148Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 1 loss 0.9316\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 2 loss 0.9258\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 3 loss 0.8967\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 4 loss 0.8837\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final epoch 5 loss 0.8432\n"
          ]
        }
      ],
      "source": [
        "full_ds = PairDataset(train_df, train_tf)\n",
        "full_loader = DataLoader(full_ds, batch_size=16, shuffle=True, num_workers=0)\n",
        "\n",
        "final_model = SiameseNet().to(DEVICE)\n",
        "\n",
        "pos = float(train_df[\"class\"].sum())\n",
        "neg = float(len(train_df) - pos)\n",
        "pos_weight = torch.tensor([neg / pos], dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.AdamW(final_model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    final_model.train()\n",
        "    total_loss = 0.0\n",
        "    for x1, x2, y in full_loader:\n",
        "        x1 = x1.to(DEVICE)\n",
        "        x2 = x2.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        logits = final_model(x1, x2)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "    print(f\"final epoch {epoch} loss {total_loss/len(full_ds):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00e33ec7",
      "metadata": {},
      "source": [
        "## Step 7: Predict for the test pairs\n",
        "\n",
        "We apply the trained model to the test pairs and write `yourname_results.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d46912c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-27T07:34:25.697780Z",
          "iopub.status.busy": "2026-01-27T07:34:25.697709Z",
          "iopub.status.idle": "2026-01-27T07:34:29.532624Z",
          "shell.execute_reply": "2026-01-27T07:34:29.532135Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pair_Num</th>\n",
              "      <th>Predicted_Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2658</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1278</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>894</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pair_Num  Predicted_Result\n",
              "0      2458                 1\n",
              "1      2172                 1\n",
              "2      2658                 0\n",
              "3      1278                 0\n",
              "4       894                 1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict on test set and write submission\n",
        "final_model.eval()\n",
        "\n",
        "test_ds = PairDataset(test_df, val_tf, is_test=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=0)\n",
        "\n",
        "all_probs = []\n",
        "with torch.no_grad():\n",
        "    for x1, x2 in test_loader:\n",
        "        x1 = x1.to(DEVICE)\n",
        "        x2 = x2.to(DEVICE)\n",
        "        logits = final_model(x1, x2)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy().astype(np.float32)\n",
        "        all_probs.append(probs)\n",
        "\n",
        "all_probs = np.concatenate(all_probs)\n",
        "\n",
        "# Turn probabilities into 0/1 predictions using best_t\n",
        "preds = (all_probs >= best_t).astype(int)\n",
        "\n",
        "out = pd.DataFrame({\n",
        "    \"Pair_Num\": test_df[\"Pair_Num\"],\n",
        "    \"Predicted_Result\": preds,\n",
        "})\n",
        "\n",
        "out_path = \"shirong_results.csv\"\n",
        "out.to_csv(out_path, index=False)\n",
        "\n",
        "out.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8041cec",
      "metadata": {},
      "source": [
        "## Notes and tips\n",
        "\n",
        "- `val_f1` is the F1 score on the validation split. Higher is better.\n",
        "- `best_t` is the best probability threshold found for F1.\n",
        "- The test file has no labels, so the output is a prediction only.\n",
        "- Rename `yourname_results.csv` to match the required naming rule."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "eoitek",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}